Instalar o localtunnel: npm install -g localtunnel

Para gerar uma URL pública do servidor local, rodar o comando: lt --port 3000

O path do webhook é /webhook

// TODO:

// 1 - Hospedar langFlow em nosso servidor (Lambda??? Não é interessante deixar no servidor raiz)

// https://github.com/langflow-ai/langflow?tab=readme-ov-file

// 2 - Hospedar webhook em cloud (Lambda??? Não é interessante deixar no servidor raiz) 

// 3 - Receber áudio do cliente, mandar para o chatGPT (tem que integrar à API) e repassar transcrição pro Flow


